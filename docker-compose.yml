

services:
  # ============================================
  # LPR DETECTION SERVICE (YOLO + OCR)
  # ============================================
  lpr_detection:
    build:
      context: ./services/lpr_detection
      dockerfile: Dockerfile
    image: gtvision/lpr_detection:latest
    container_name: gtvision_lpr_detection
    command: python main.py
    environment:
      BACKEND_URL: http://backend:8000
      ADMIN_API_KEY: ${ADMIN_API_KEY}
      REDIS_URL: redis://redis_cache:6379/4
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
    ports:
      - "5000:5000"
    volumes:
      - lpr_captures:/app/captures
      - lpr_training:/app/pending_training
      - lpr_webhooks:/app/received_webhooks
    depends_on:
      backend:
        condition: service_healthy
      redis_cache:
        condition: service_healthy
    networks:
      - gtvision_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # ============================================
  # AI DETECTION SERVICE (FastAPI)
  # ============================================
  ai_detection:
    build:
      context: ./services/ai_detection
      dockerfile: Dockerfile
      args:
        BUILDKIT_INLINE_CACHE: 1
    image: gtvision/ai_detection:latest
    container_name: gtvision_ai_detection
    command: uvicorn main:app --host 0.0.0.0 --port 8002 --workers 1 --timeout-keep-alive 5 --limit-concurrency 10
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 3G
        reservations:
          cpus: '0.5'
          memory: 512M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    environment:
      RABBITMQ_URL: amqp://${RABBITMQ_USER}:${RABBITMQ_PASS}@rabbitmq:5672/
      REDIS_URL: redis://redis_cache:6379/3
      DB_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres_db/${POSTGRES_DB}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_REGION: ${AWS_REGION:-us-east-1}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      PYTHONUNBUFFERED: 1
    ports:
      - "8002:8002"
    depends_on:
      rabbitmq:
        condition: service_healthy
      redis_cache:
        condition: service_healthy
      postgres_db:
        condition: service_healthy
    networks:
      - gtvision_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # ============================================
  # STREAMING SERVICE (FastAPI)
  # ============================================
  streaming:
    build:
      context: ./services/streaming
      dockerfile: Dockerfile
    image: gtvision/streaming:latest
    container_name: gtvision_streaming
    command: uvicorn main:app --host 0.0.0.0 --port 8001 --workers 2
    deploy:
      resources:
        limits:
          cpus: '1.5'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 256M
    environment:
      MEDIAMTX_API_URL: http://mediamtx:9997
      MEDIAMTX_HLS_URL: http://mediamtx:8888
      MEDIAMTX_WEBRTC_URL: http://mediamtx:8889
      MEDIAMTX_API_USER: ${MEDIAMTX_API_USER:-mediamtx_api_user}
      MEDIAMTX_API_PASS: ${MEDIAMTX_API_PASS}
      REDIS_URL: redis://redis_cache:6379/2
      RABBITMQ_URL: amqp://${RABBITMQ_USER}:${RABBITMQ_PASS}@rabbitmq:5672/
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
    ports:
      - "8001:8001"
    depends_on:
      mediamtx:
        condition: service_healthy
      redis_cache:
        condition: service_healthy
    networks:
      - gtvision_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # ============================================
  # BACKEND (Django API)
  # ============================================
  backend:
    build:
      context: .
      dockerfile: ./backend/deploy/Dockerfile
    container_name: gtvision_backend
    command: sh -c "python manage.py migrate --noinput && python manage.py collectstatic --noinput && python manage.py runserver 0.0.0.0:8000"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
        reservations:
          cpus: '0.1'
          memory: 256M
    ports:
      - "8000:8000"
    volumes:
      - ./backend/logs:/app/logs
      - backend_static:/app/staticfiles
      - backend_media:/app/media
      - mediamtx_recordings:/recordings:ro
    env_file: .env
    environment:
      DB_HOST: postgres_db
      DB_PORT: 5432
      REDIS_HOST: redis_cache
      CELERY_BROKER_URL: amqp://${RABBITMQ_USER}:${RABBITMQ_PASS}@rabbitmq:5672//
      STREAMING_SERVICE_URL: http://streaming:8001
    depends_on:
      postgres_db:
        condition: service_healthy
      redis_cache:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    networks:
      - gtvision_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/admin/login/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # ============================================
  # BACKEND WORKER (Celery) - DESABILITADO
  # ============================================
  # backend_worker:
  #   build:
  #     context: .
  #     dockerfile: ./backend/Dockerfile
  #   container_name: gtvision_backend_worker
  #   command: sh -c "python wait_for_db.py && celery -A config worker --loglevel=info"
  #   env_file: .env
  #   environment:
  #     CELERY_BROKER_URL: amqp://${RABBITMQ_USER}:${RABBITMQ_PASS}@rabbitmq:5672//
  #   depends_on:
  #     backend:
  #       condition: service_healthy
  #     rabbitmq:
  #       condition: service_healthy
  #   networks:
  #     - gtvision_network
  #   restart: unless-stopped

  # ============================================
  # FRONTEND (Vite / React)
  # ============================================
  frontend:
    image: node:20-slim
    container_name: gtvision_frontend
    working_dir: /app
    volumes:
      - ./frontend:/app
      - /app/node_modules
    command: sh -c "npm install --legacy-peer-deps && npm run dev -- --host 0.0.0.0 --port 5173"
    networks:
      - gtvision_network
    restart: unless-stopped

  # ============================================
  # KONG API GATEWAY
  # ============================================
  kong:
    image: kong:3.5
    container_name: gtvision_kong
    environment:
      KONG_DATABASE: "off"
      KONG_DECLARATIVE_CONFIG: /etc/kong/kong.yml
      KONG_PROXY_LISTEN: 0.0.0.0:8000
    volumes:
      - ./kong/kong.yml:/etc/kong/kong.yml:ro
    depends_on:
      backend:
        condition: service_started
      streaming:
        condition: service_healthy
    networks:
      - gtvision_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "kong", "health"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ============================================
  # HAPROXY
  # ============================================
  haproxy:
    image: haproxy:2.9-alpine
    container_name: gtvision_haproxy
    ports:
      - "80:80"
      - "8404:8404"
    volumes:
      - ./haproxy/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
    depends_on:
      kong:
        condition: service_started
      streaming:
        condition: service_healthy
      frontend:
        condition: service_started
    networks:
      - gtvision_network
    restart: unless-stopped

  # ============================================
  # NGINX (STATIC)
  # ============================================
  nginx:
    image: nginx:alpine
    container_name: gtvision_nginx
    volumes:
      - ./nginx/nginx.simple.conf:/etc/nginx/nginx.conf:ro
      - backend_static:/var/www/static:ro
      - backend_media:/var/www/media:ro
    networks:
      - gtvision_network

  # ============================================
  # POSTGRES
  # ============================================
  postgres_db:
    image: postgres:15-alpine
    container_name: gtvision_postgres
    env_file: .env
    ports:
      - "5432:5432"
    volumes:
      - gtvision_pg_data:/var/lib/postgresql/data
    networks:
      - gtvision_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # ============================================
  # REDIS
  # ============================================
  redis_cache:
    image: redis:7-alpine
    container_name: gtvision_redis
    networks:
      - gtvision_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # ============================================
  # RABBITMQ
  # ============================================
  rabbitmq:
    image: rabbitmq:3.13-management-alpine
    container_name: gtvision_rabbitmq
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASS}
      RABBITMQ_DEFAULT_VHOST: /
      RABBITMQ_ERLANG_COOKIE: GTVISIONRABBITMQCOOKIE
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    networks:
      - gtvision_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "check_running"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # ============================================
  # PROMETHEUS
  # ============================================
  prometheus:
    image: prom/prometheus:latest
    container_name: gtvision_prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./config/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./config/prometheus/alerts.yml:/etc/prometheus/alerts.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    networks:
      - gtvision_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # ============================================
  # MEDIAMTX
  # ============================================
  mediamtx:
    image: bluenviron/mediamtx:latest-ffmpeg
    container_name: gtvision_mediamtx
    env_file: .env
    ports:
      - "8888:8888"  # HLS
      - "8889:8889"  # WebRTC
      - "9997:9997"  # API
    volumes:
      - ./mediamtx.yml:/mediamtx.yml:ro
      - mediamtx_recordings:/recordings
    deploy:
      resources:
        limits:
          cpus: '2.5'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 512M
    networks:
      - gtvision_network
    environment:
      MEDIAMTX_API_USER: ${MEDIAMTX_API_USER}
      MEDIAMTX_API_PASS: ${MEDIAMTX_API_PASS}
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "--header=Authorization: Basic bWVkaWFtdHhfYXBpX3VzZXI6R3RWIXNpb25NZWQxYU1UWCQyMDI1", "http://localhost:9997/v3/config/global/get"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s



# ============================================
# VOLUMES
# ============================================
volumes:
  gtvision_pg_data:
  backend_static:
  backend_media:
  mediamtx_recordings:
  rabbitmq_data:
  prometheus_data:
  lpr_captures:
  lpr_training:
  lpr_webhooks:

# ============================================
# NETWORK
# ============================================
networks:
  gtvision_network:
    driver: bridge
