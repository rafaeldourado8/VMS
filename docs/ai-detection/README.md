# ğŸ¤– Sistema de DetecÃ§Ã£o de IA - Arquitetura Completa

Sistema inteligente de detecÃ§Ã£o de placas veiculares (LPR) com pipeline otimizado para alta precisÃ£o e baixo custo.

---

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [Arquitetura](#arquitetura)
- [Componentes](#componentes)
- [Pipeline de Processamento](#pipeline-de-processamento)
- [AnÃ¡lise dos Sistemas Existentes](#anÃ¡lise-dos-sistemas-existentes)
- [DecisÃµes TÃ©cnicas](#decisÃµes-tÃ©cnicas)
- [ImplementaÃ§Ã£o](#implementaÃ§Ã£o)

---

## ğŸ¯ VisÃ£o Geral

### Objetivo
Detectar e reconhecer placas veiculares em tempo real com:
- **Alta precisÃ£o**: Consenso de mÃºltiplas leituras (â‰¥60%)
- **Baixa latÃªncia**: WebRTC para IA (vs HLS para usuÃ¡rios)
- **Baixo custo**: CPU-only, motion detection, frame skipping
- **Zero duplicatas**: Cache Redis com TTL de 5 minutos

### Fluxo Simplificado
```
Camera RTSP â†’ MediaMTX â†’ WebRTC (IA) â†’ Pipeline â†’ Backend
                       â””â†’ HLS (UsuÃ¡rios)
```

### MÃ©tricas Alvo
- **LatÃªncia**: <500ms (WebRTC vs 10-30s HLS)
- **PrecisÃ£o**: >95% (consenso multi-round)
- **FPS**: 1-3 FPS (vs 30 FPS original = 90% economia)
- **CPU**: <30% por cÃ¢mera (motion detection + frame skipping)

---

## ğŸ—ï¸ Arquitetura

### Fluxo Detalhado

```
Camera RTSP
   â†“
MediaMTX
   â”œâ”€ WebRTC (IA â€“ low latency, FPS controlado)
   â””â”€ HLS (UsuÃ¡rios) (jÃ¡ funciona, nunca mexer)
   â†“
Frame Extractor (1-3 FPS)
   â†“
Frame Buffer (Queue AssÃ­ncrona)
   â†“
Motion Detection? â”€â”€NOâ”€â”€> Drop Frame (70-80%)
   â†“ YES
Vehicle Detection? â”€â”€NOâ”€â”€> Drop Frame
   â†“ YES
Multi-Object Tracking (ByteTrack)
   â†“
Track Buffer (10-30 frames por veÃ­culo)
   â†“
Frame Quality Scoring (Blur/Angle/Contrast/Size)
   â†“
Best Frame Selection (Top 3)
   â†“
Plate Detection (YOLO LPR)
   â†“
OCR (Fast-Plate-OCR)
   â†“
Consensus Engine (3-5 leituras, â‰¥60%)
   â†“
Duplicado? â”€â”€YESâ”€â”€> Drop Event
   â†“ NO
Dedup Cache (Redis TTL 5min)
   â†“
Event Producer (RabbitMQ)
   â†“
Backend API Consumer
```

### Estrutura de DiretÃ³rios

```
services/ai_detection/
â”œâ”€â”€ core/                       # Componentes principais
â”‚   â”œâ”€â”€ motion_detector.py      # DetecÃ§Ã£o de movimento
â”‚   â”œâ”€â”€ vehicle_detector.py     # DetecÃ§Ã£o de veÃ­culos
â”‚   â”œâ”€â”€ plate_detector.py       # DetecÃ§Ã£o de placas
â”‚   â”œâ”€â”€ ocr_engine.py           # Reconhecimento OCR
â”‚   â”œâ”€â”€ tracker.py              # Rastreamento multi-objeto
â”‚   â””â”€â”€ quality_scorer.py       # AvaliaÃ§Ã£o de qualidade
â”‚
â”œâ”€â”€ pipeline/                   # Pipeline de processamento
â”‚   â”œâ”€â”€ frame_extractor.py      # ExtraÃ§Ã£o de frames WebRTC
â”‚   â”œâ”€â”€ frame_buffer.py         # Buffer assÃ­ncrono
â”‚   â”œâ”€â”€ consensus_engine.py     # Motor de consenso
â”‚   â””â”€â”€ dedup_cache.py          # Cache de deduplicaÃ§Ã£o
â”‚
â”œâ”€â”€ integration/                # IntegraÃ§Ãµes externas
â”‚   â”œâ”€â”€ mediamtx_client.py      # Cliente WebRTC
â”‚   â”œâ”€â”€ api_client.py           # Cliente Backend API
â”‚   â””â”€â”€ rabbitmq_producer.py    # Produtor de eventos
â”‚
â”œâ”€â”€ api/                        # API de controle
â”‚   â””â”€â”€ control_api.py          # Flask API
â”‚
â”œâ”€â”€ config/                     # ConfiguraÃ§Ãµes
â”‚   â””â”€â”€ settings.py             # VariÃ¡veis de ambiente
â”‚
â”œâ”€â”€ main.py                     # Entry point
â”œâ”€â”€ Dockerfile                  # Container otimizado
â””â”€â”€ requirements.txt            # DependÃªncias
```

---

## ğŸ”§ Componentes

### [1. Frame Extractor](./components/FRAME_EXTRACTOR.md)
**FunÃ§Ã£o**: Extrai frames do stream WebRTC do MediaMTX

**Input**: WebRTC stream (baixa latÃªncia)  
**Output**: Frames RGB (1-3 FPS)

**CaracterÃ­sticas**:
- FPS throttle configurÃ¡vel (1-3 FPS)
- Economia de 90% de processamento vs 30 FPS
- ReconexÃ£o automÃ¡tica em caso de falha

---

### [2. Frame Buffer](./components/FRAME_BUFFER.md)
**FunÃ§Ã£o**: Queue assÃ­ncrona para desacoplar captura de processamento

**Input**: Frames do extractor  
**Output**: Frames para motion detection

**CaracterÃ­sticas**:
- Queue thread-safe (asyncio)
- Tamanho mÃ¡ximo configurÃ¡vel
- Drop de frames antigos se buffer cheio

---

### [3. Motion Detection](./components/MOTION_DETECTION.md)
**FunÃ§Ã£o**: Filtra frames sem movimento (economia de CPU)

**Input**: Frames do buffer  
**Output**: Frames com movimento detectado

**CaracterÃ­sticas**:
- OpenCV MOG2 (Background Subtraction)
- Economia de 70-80% de processamento
- Sensibilidade configurÃ¡vel

**Algoritmo**:
```python
# Detecta mudanÃ§as entre frames
# Se mudanÃ§a < threshold â†’ Drop frame
# Se mudanÃ§a â‰¥ threshold â†’ Processa
```

---

### [4. Vehicle Detection](./components/VEHICLE_DETECTION.md)
**FunÃ§Ã£o**: Detecta veÃ­culos no frame usando YOLO

**Input**: Frames com movimento  
**Output**: Bounding boxes de veÃ­culos

**CaracterÃ­sticas**:
- YOLOv8n (nano - rÃ¡pido)
- Classes: car, truck, motorcycle, bus
- Confidence threshold: >0.5

**OtimizaÃ§Ãµes**:
- Processa 1 a cada 3 frames (frame skipping)
- CPU-only (PyTorch)
- Modelo compacto (6MB)

---

### [5. Multi-Object Tracker](./components/TRACKER.md)
**FunÃ§Ã£o**: Rastreia veÃ­culos entre frames para acumular leituras

**Input**: DetecÃ§Ãµes de veÃ­culos  
**Output**: Tracks completos (veÃ­culo saiu do FOV)

**CaracterÃ­sticas**:
- ByteTrack ou DeepSORT
- IoU-based matching (threshold: 0.3)
- Timeout: 5 segundos sem detecÃ§Ã£o

**Por que Ã© importante**:
- Acumula 10-30 frames por veÃ­culo
- Permite consenso de mÃºltiplas leituras
- Reduz falsos positivos

---

### [6. Track Buffer](./components/TRACK_BUFFER.md)
**FunÃ§Ã£o**: Armazena frames de cada veÃ­culo rastreado

**Input**: Frames do track ativo  
**Output**: Conjunto de frames quando veÃ­culo sai do FOV

**CaracterÃ­sticas**:
- 10-30 frames por veÃ­culo
- Armazena frame + metadata (timestamp, bbox)
- Libera memÃ³ria apÃ³s processamento

---

### [7. Quality Scorer](./components/QUALITY_SCORER.md)
**FunÃ§Ã£o**: Avalia qualidade de cada frame para escolher o melhor

**Input**: Frames do track buffer  
**Output**: Score de qualidade (0-100)

**MÃ©tricas**:

1. **Blur Detection** (Laplacian Variance)
   - Frame nÃ­tido: score alto
   - Frame borrado: score baixo

2. **Ã‚ngulo da Placa** (Perspectiva)
   - Placa frontal: score alto
   - Placa lateral: score baixo

3. **Contraste** (Histograma)
   - Alto contraste: score alto
   - Baixo contraste: score baixo

4. **Tamanho da Placa** (Pixels)
   - Placa grande: score alto
   - Placa pequena: score baixo

**FÃ³rmula**:
```
Score = (blur Ã— 0.3) + (angle Ã— 0.3) + (contrast Ã— 0.2) + (size Ã— 0.2)
```

---

### [8. Best Frame Selection](./components/BEST_FRAME.md)
**FunÃ§Ã£o**: Seleciona o melhor frame do track para OCR

**Input**: Frames + scores  
**Output**: Frame com maior score

**EstratÃ©gia**:
- Ordena frames por score
- Seleciona top 3
- Usa todos para consenso

---

### [9. Plate Detection](./components/PLATE_DETECTION.md)
**FunÃ§Ã£o**: Detecta placa no frame do veÃ­culo

**Input**: Frame do veÃ­culo  
**Output**: Bounding box da placa

**CaracterÃ­sticas**:
- YOLO fine-tuned para placas
- Modelos disponÃ­veis: yolov8n/s/m/l/x
- Confidence threshold: >0.6

**PrÃ©-processamento**:
- Crop da regiÃ£o do veÃ­culo
- Resize para tamanho padrÃ£o
- ConversÃ£o para escala de cinza

---

### [10. OCR Engine](./components/OCR_ENGINE.md)
**FunÃ§Ã£o**: Reconhece texto da placa

**Input**: Imagem da placa  
**Output**: Texto da placa + confidence

**CaracterÃ­sticas**:
- Fast-Plate-OCR (ONNX runtime)
- Suporte multi-paÃ­s (Brasil, Argentina, etc)
- CPU-optimized

**Alternativas avaliadas**:
- âŒ Tesseract: Lento, menos preciso
- âŒ PaddleOCR: Complexo, GPU-dependent
- âœ… Fast-Plate-OCR: RÃ¡pido, preciso, CPU-only

---

### [11. Consensus Engine](./components/CONSENSUS_ENGINE.md)
**FunÃ§Ã£o**: Determina placa correta por votaÃ§Ã£o

**Input**: 3-5 leituras de OCR  
**Output**: Placa validada + confidence

**EstratÃ©gias**:

1. **Simple Majority** (Maioria Simples)
   - Se placa aparece >50% â†’ Vence
   - Exemplo: [ABC1234, ABC1234, ABC1234, XYZ5678] â†’ ABC1234

2. **Similarity Voting** (Similaridade)
   - Agrupa placas similares (>80%)
   - Exemplo: [ABC1234, ABC1Z34, ABC1234] â†’ ABC1234
   - Usa difflib.SequenceMatcher

3. **Highest Confidence** (Fallback)
   - Se sem consenso â†’ Maior confidence
   - Exemplo: [ABC1234(0.9), XYZ5678(0.7)] â†’ ABC1234

**Requisitos**:
- MÃ­nimo 3 leituras
- Consenso â‰¥60%
- Confidence mÃ­nima: 0.75

---

### [12. Deduplication Cache](./components/DEDUP_CACHE.md)
**FunÃ§Ã£o**: Evita enviar mesma placa mÃºltiplas vezes

**Input**: Placa validada  
**Output**: Placa Ãºnica (se nÃ£o duplicada)

**CaracterÃ­sticas**:
- Redis com TTL de 5 minutos
- Key: `plate:{camera_id}:{plate_text}`
- Similaridade: 80% (SequenceMatcher)

**Exemplo**:
```
10:00 â†’ ABC1234 (enviado)
10:02 â†’ ABC1234 (bloqueado - duplicata)
10:06 â†’ ABC1234 (enviado - TTL expirou)
```

---

### [13. Event Producer](./components/EVENT_PRODUCER.md)
**FunÃ§Ã£o**: Envia eventos para o Backend via RabbitMQ

**Input**: DetecÃ§Ã£o validada  
**Output**: Mensagem na fila

**Payload**:
```json
{
  "plate": "ABC1234",
  "confidence": 0.92,
  "method": "simple_majority",
  "camera_id": 1,
  "timestamp": "2024-01-15T10:30:00Z",
  "image_path": "/captures/abc1234_123456.jpg",
  "metadata": {
    "track_id": 42,
    "frames_analyzed": 15,
    "best_frame_score": 87.5
  }
}
```

---

## ğŸ”„ Pipeline de Processamento

### Taxas de Drop (OtimizaÃ§Ã£o)

| Etapa | Drop Rate | Frames Restantes |
|-------|-----------|------------------|
| Input (30 FPS) | - | 30 FPS |
| Frame Extractor | 90% | 3 FPS |
| Motion Detection | 70% | 0.9 FPS |
| Vehicle Detection | 50% | 0.45 FPS |
| **Total** | **98.5%** | **0.45 FPS** |

**Resultado**: Processa apenas 1.5% dos frames originais!

---

## ğŸ“Š AnÃ¡lise dos Sistemas Existentes

### Sistema 1: `lpr_detection` (Atual)

**LocalizaÃ§Ã£o**: `services/lpr_detection/`

#### âœ… Pontos Fortes

1. **Tracking de VeÃ­culos** (`tracking.py`)
   - IoU-based matching
   - Timeout configurÃ¡vel (5s)
   - Acumula detecÃ§Ãµes por veÃ­culo

2. **Sistema de VotaÃ§Ã£o** (`voting.py`)
   - 3 estratÃ©gias (majority, similarity, confidence)
   - Consenso configurÃ¡vel
   - ClassificaÃ§Ã£o de confianÃ§a

3. **Fast-Plate-OCR** (`detection.py`)
   - ONNX runtime (rÃ¡pido)
   - CPU-optimized
   - Suporte multi-paÃ­s

4. **IntegraÃ§Ã£o Backend** (`main.py`, `api_client.py`)
   - API REST para controle
   - RabbitMQ para eventos
   - PostgreSQL para persistÃªncia

5. **Docker Otimizado** (`Dockerfile.optimized`)
   - Multi-stage build
   - CPU-only PyTorch
   - Health checks

#### âŒ Pontos Fracos

1. **Sem Motion Detection**
   - Processa todos os frames
   - DesperdÃ­cio de CPU

2. **Sem Quality Scoring**
   - NÃ£o escolhe melhor frame
   - Pode usar frames ruins

3. **Sem DeduplicaÃ§Ã£o**
   - Pode enviar duplicatas
   - Sem cache Redis

4. **RTSP Direto**
   - Alta latÃªncia
   - Sem WebRTC

5. **Pipeline Simples**
   - Sem buffer assÃ­ncrono
   - Sem validaÃ§Ã£o multi-round

---

### Sistema 2: `alpr-yolov8-python-ocr` (Clonado)

**LocalizaÃ§Ã£o**: `services/alpr-yolov8-python-ocr/`

#### âœ… Pontos Fortes

1. **Motion Detection** (`server.py`)
   - OpenCV MOG2
   - Background subtraction
   - Economia de 70-80% CPU

2. **Quality Scoring** (`utils.py`)
   - Blur detection (Laplacian)
   - PrÃ©-processamento avanÃ§ado
   - Contour detection

3. **ValidaÃ§Ã£o Multi-Round** (`server.py`)
   - 3-5 leituras por veÃ­culo
   - Consenso â‰¥60%
   - Filtro de resultados

4. **DeduplicaÃ§Ã£o Temporal** (`server.py`)
   - Cache in-memory (5min)
   - Similaridade 80%
   - Evita duplicatas

5. **WebSocket Server** (`server.py`)
   - Tempo real
   - MÃºltiplos clientes
   - ReconexÃ£o automÃ¡tica

6. **PrÃ©-processamento AvanÃ§ado** (`utils.py`)
   - Gaussian blur
   - Threshold adaptativo
   - Morphological operations
   - Contour extraction

#### âŒ Pontos Fracos

1. **Sem Tracking de VeÃ­culos**
   - NÃ£o rastreia entre frames
   - Perde contexto

2. **Sem IntegraÃ§Ã£o VMS**
   - NÃ£o usa Backend API
   - NÃ£o usa RabbitMQ
   - MSSQL (nÃ£o PostgreSQL)

3. **WebSocket (nÃ£o ideal)**
   - NÃ£o Ã© padrÃ£o do VMS
   - Complexidade extra

4. **Tesseract OCR**
   - Mais lento que Fast-Plate-OCR
   - Menos preciso
   - Multi-thread complexo

5. **Sem Controle de CÃ¢meras**
   - NÃ£o tem API REST
   - NÃ£o integra com MediaMTX

---

## ğŸ¯ DecisÃµes TÃ©cnicas

### O que USAR de cada sistema

#### Do `lpr_detection`:
- âœ… **Tracking** (IoU-based) â†’ Melhorar com ByteTrack
- âœ… **Voting System** â†’ Manter e expandir
- âœ… **Fast-Plate-OCR** â†’ Manter (melhor que Tesseract)
- âœ… **API Client + RabbitMQ** â†’ Manter
- âœ… **Docker Otimizado** â†’ Manter
- âœ… **Flask API** â†’ Manter para controle

#### Do `alpr-yolov8-python-ocr`:
- âœ… **Motion Detection** (MOG2) â†’ Adicionar
- âœ… **Quality Scoring** â†’ Adicionar
- âœ… **Multi-round Validation** â†’ Adicionar
- âœ… **Deduplication Cache** â†’ Adicionar (migrar para Redis)
- âœ… **PrÃ©-processamento AvanÃ§ado** â†’ Adicionar

### O que NÃƒO usar

#### Do `alpr-yolov8-python-ocr`:
- âŒ **WebSocket Server** â†’ Usar RabbitMQ
- âŒ **Tesseract OCR** â†’ Usar Fast-Plate-OCR
- âŒ **MSSQL** â†’ Usar PostgreSQL do VMS
- âŒ **In-memory Cache** â†’ Usar Redis

---

## ğŸš€ ImplementaÃ§Ã£o

### Fases de Desenvolvimento

#### **Fase 1: Setup Base** (2-3 dias)
- [ ] Criar estrutura `ai_detection/`
- [ ] Configurar Docker + requirements
- [ ] Setup Redis para cache
- [ ] Configurar variÃ¡veis de ambiente

#### **Fase 2: Core Components** (3-4 dias)
- [ ] `motion_detector.py` (OpenCV MOG2)
- [ ] `vehicle_detector.py` (YOLO)
- [ ] `plate_detector.py` (YOLO LPR)
- [ ] `ocr_engine.py` (Fast-Plate-OCR)
- [ ] `tracker.py` (ByteTrack)
- [ ] `quality_scorer.py` (Blur/Angle/Contrast)

#### **Fase 3: Pipeline** (3-4 dias)
- [ ] `frame_extractor.py` (WebRTC)
- [ ] `frame_buffer.py` (Async queue)
- [ ] `consensus_engine.py` (Voting)
- [ ] `dedup_cache.py` (Redis)

#### **Fase 4: Integration** (2-3 dias)
- [ ] `mediamtx_client.py` (WebRTC consumer)
- [ ] `api_client.py` (Backend API)
- [ ] `rabbitmq_producer.py` (Event queue)

#### **Fase 5: API & Control** (1-2 dias)
- [ ] `control_api.py` (Flask)
- [ ] Health checks
- [ ] Prometheus metrics

#### **Fase 6: Testing** (2-3 dias)
- [ ] Testes unitÃ¡rios
- [ ] Testes de integraÃ§Ã£o
- [ ] Benchmark de performance
- [ ] Ajuste de thresholds

#### **Fase 7: Documentation** (1-2 dias)
- [ ] DocumentaÃ§Ã£o de componentes
- [ ] Guia de configuraÃ§Ã£o
- [ ] Troubleshooting
- [ ] Diagramas Excalidraw

---

## ğŸ“ˆ MÃ©tricas de Sucesso

### Performance
- **LatÃªncia**: <500ms (vs 10-30s HLS)
- **Throughput**: 10-20 cÃ¢meras por servidor
- **CPU**: <30% por cÃ¢mera
- **MemÃ³ria**: <500MB por cÃ¢mera

### Qualidade
- **PrecisÃ£o**: >95% (consenso)
- **Recall**: >90% (nÃ£o perde veÃ­culos)
- **Falsos Positivos**: <5%
- **Duplicatas**: 0% (cache Redis)

### Custo
- **CPU**: $500/mÃªs (vs $10k GPU)
- **Banda**: MÃ­nima (WebRTC local)
- **Storage**: MÃ­nimo (sÃ³ best frames)

---

## ğŸ”— Links Relacionados

- [Componentes Detalhados](./components/)
- [Roadmap](../phases/README.md)
- [System Overview](../SYSTEM_OVERVIEW.md)
