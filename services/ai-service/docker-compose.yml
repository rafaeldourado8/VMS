# ======================================================
# GT-Vision AI Service - Full Stack (IA + Cache)
# ======================================================
version: '3.9'

services:
  # Serviço de Cache (Obrigatório para a comunicação entre serviços)
  redis_cache:
    image: redis:7-alpine
    container_name: ai_redis_cache
    command: redis-server --appendonly yes
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  # Serviço de Inteligência Artificial
  ai-service:
    build:
      context: .
      dockerfile: Dockerfile
    image: gtvision/ai-service:latest
    container_name: gtvision_ai
    depends_on:
      redis_cache:
        condition: service_healthy # Só inicia a IA quando o Redis estiver pronto
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 1G
    ports:
      - "8080:8000"    # API
      - "9092:9090"    # Metrics
    environment:
      - REDIS_HOST=redis_cache  # Nome do serviço acima
      - REDIS_PORT=6379
      - REDIS_DB=1
      - WORKERS=${AI_WORKERS:-4}
      - BATCH_SIZE=${AI_BATCH_SIZE:-8}
      - CONFIDENCE_THRESHOLD=${AI_CONFIDENCE:-0.5}
      - ENABLE_GPU=${ENABLE_GPU:-false}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - ./models:/app/models
      - ai_logs:/app/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

volumes:
  ai_logs:
  redis_data: # Volume para não perder os dados do cache se o container cair